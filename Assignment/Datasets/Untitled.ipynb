{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ca5cf7-c91c-4ced-acdd-3cca5fc957ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f126eb6-a140-4b9d-9390-d94f895702fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\cheru\\Desktop\\glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748d61e-6ffc-4d57-96e3-bf8759032eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries at the beginning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib  # For saving the model\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# =========================\n",
    "# Step 1: Load Data\n",
    "# =========================\n",
    "df = pd.read_csv('airbnb_nyc_listings.csv')  # Replace with your dataset path\n",
    "\n",
    "# Basic info\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nData Description:\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# =========================\n",
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "# =========================\n",
    "\n",
    "# Histogram of Prices\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['price'], bins=50, kde=True)\n",
    "plt.title('Distribution of Airbnb Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to detect outliers\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x=df['price'])\n",
    "plt.title('Boxplot of Airbnb Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.show()\n",
    "\n",
    "# Price vs. Number of Bedrooms scatterplot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='bedrooms', y='price', data=df)\n",
    "plt.title('Price vs. Number of Bedrooms')\n",
    "plt.xlabel('Bedrooms')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Step 3: Data Preprocessing\n",
    "# =========================\n",
    "\n",
    "# Check missing data\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Fill missing numerical data with median\n",
    "num_features = ['price', 'bedrooms', 'bathrooms', 'number_of_reviews', 'review_scores_rating']\n",
    "for col in num_features:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical data with 'Missing'\n",
    "cat_features = ['neighbourhood', 'room_type', 'property_type']\n",
    "for col in cat_features:\n",
    "    df[col].fillna('Missing', inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[num_features] = scaler.fit_transform(df_encoded[num_features])\n",
    "\n",
    "# =========================\n",
    "# Step 4: Feature Engineering\n",
    "# =========================\n",
    "\n",
    "# Define price categories for analysis\n",
    "price_bins = [0, 100, 200, 300, 400, 500, np.inf]\n",
    "price_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High', 'Luxury']\n",
    "df['price_category'] = pd.cut(df['price'], bins=price_bins, labels=price_labels)\n",
    "\n",
    "# Visualize distribution of price categories\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='price_category', data=df, order=price_labels)\n",
    "plt.title('Number of Listings per Price Category')\n",
    "plt.xlabel('Price Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Step 5: Feature Range Analysis per Price Category\n",
    "# =========================\n",
    "\n",
    "for category in price_labels:\n",
    "    subset = df[df['price_category'] == category]\n",
    "    print(f\"\\n--- {category} Listings ---\")\n",
    "    print(f\"Count: {len(subset)}\")\n",
    "    \n",
    "    # Numerical features\n",
    "    print(\"\\nNumerical feature ranges:\")\n",
    "    for feature in ['review_scores_rating', 'number_of_reviews', 'bedrooms', 'bathrooms']:\n",
    "        print(f\"{feature}: {subset[feature].min()} - {subset[feature].max()}\")\n",
    "    \n",
    "    # Categorical feature distributions\n",
    "    print(\"\\nCategorical feature distributions:\")\n",
    "    for feature in ['neighbourhood', 'room_type', 'property_type']:\n",
    "        print(f\"\\n{feature} distribution:\")\n",
    "        print(subset[feature].value_counts())\n",
    "\n",
    "# =========================\n",
    "# Step 6: Prepare Data for Modeling\n",
    "# =========================\n",
    "\n",
    "# Drop the original 'price' column from features\n",
    "X = df_encoded.drop(['price', 'id', 'name', 'price_category'], axis=1, errors='ignore')\n",
    "y = df['price']  # Use original scale for modeling\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Step 7: Model Training and Tuning\n",
    "# =========================\n",
    "\n",
    "# Example: Random Forest with Grid Search\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# =========================\n",
    "# Step 8: Model Evaluation\n",
    "# =========================\n",
    "\n",
    "# Predict with the best model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R^2: {r2:.2f}\")\n",
    "\n",
    "# Plot predicted vs actual prices\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs. Predicted Prices')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Step 9: Save the Best Model\n",
    "# =========================\n",
    "\n",
    "joblib.dump(best_rf, 'bnb_price_prediction_model.pkl')\n",
    "print(\"Model saved as 'bnb_price_prediction_model.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
